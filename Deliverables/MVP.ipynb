{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "happy-xerox",
   "metadata": {},
   "source": [
    "## Plant Classification MVP\n",
    "\n",
    "This project involves using neural networks and transfer learning to classify leaves by plant type. There are 11 classes total. \n",
    "\n",
    "This notebook outlines initial modeling. A simple baseline neural network will be built."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "imperial-madagascar",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "58892288/58889256 [==============================] - 4s 0us/step\n",
      "58900480/58889256 [==============================] - 4s 0us/step\n"
     ]
    }
   ],
   "source": [
    "#transfer learning model\n",
    "from tensorflow import keras\n",
    "from keras.applications.vgg16 import VGG16\n",
    "\n",
    "conv_base = VGG16(weights='imagenet',\n",
    "                  include_top=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "explicit-university",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1592 images belonging to 11 classes.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "base_dir = '/Users/mehikapatel/Plant_NN_Project/data'\n",
    "\n",
    "train_dir = os.path.join(base_dir, 'train')\n",
    "validation_dir = os.path.join(base_dir, 'validation')\n",
    "test_dir = os.path.join(base_dir, 'test')\n",
    "\n",
    "datagen = ImageDataGenerator(rescale=1./255)\n",
    "batch_size = 20\n",
    "\n",
    "def extract_features(directory, sample_count):\n",
    "    features = np.zeros(shape=(sample_count, 4, 4, 512))\n",
    "    labels = np.zeros(shape=(sample_count))\n",
    "    generator = datagen.flow_from_directory(\n",
    "        directory,\n",
    "        target_size=(150, 150),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='binary')\n",
    "    i = 0\n",
    "    for inputs_batch, labels_batch in generator:\n",
    "        features_batch = conv_base.predict(inputs_batch)\n",
    "        features[i * batch_size : (i + 1) * batch_size] = features_batch\n",
    "        labels[i * batch_size : (i + 1) * batch_size] = labels_batch\n",
    "        i += 1\n",
    "        if i * batch_size >= sample_count:\n",
    "            # Note that since generators yield data indefinitely in a loop,\n",
    "            # we must `break` after every image has been seen once.\n",
    "            break\n",
    "    return features, labels\n",
    "\n",
    "train_features, train_labels = extract_features(train_dir, 1592)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "theoretical-climb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 341 images belonging to 11 classes.\n"
     ]
    }
   ],
   "source": [
    "validation_features, validation_labels = extract_features(validation_dir, 341) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "loving-raise",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 344 images belonging to 11 classes.\n"
     ]
    }
   ],
   "source": [
    "test_features, test_labels = extract_features(test_dir, 344) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "naughty-homeless",
   "metadata": {},
   "outputs": [],
   "source": [
    "#flatten images:\n",
    "\n",
    "train_features = np.reshape(train_features, (1592, 4 * 4 * 512))\n",
    "validation_features = np.reshape(validation_features, (341, 4 * 4 * 512))\n",
    "test_features = np.reshape(test_features, (344, 4 * 4 * 512))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "improved-government",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mehikapatel/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:374: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "80/80 [==============================] - 8s 16ms/step - loss: -27.7537 - acc: 0.1011 - val_loss: -82.8494 - val_acc: 0.0968\n",
      "Epoch 2/30\n",
      "80/80 [==============================] - 1s 12ms/step - loss: -100.6260 - acc: 0.0927 - val_loss: -153.4381 - val_acc: 0.0968\n",
      "Epoch 3/30\n",
      "80/80 [==============================] - 1s 11ms/step - loss: -177.5466 - acc: 0.0892 - val_loss: -228.2289 - val_acc: 0.0968\n",
      "Epoch 4/30\n",
      "80/80 [==============================] - 1s 11ms/step - loss: -242.2584 - acc: 0.1080 - val_loss: -306.1248 - val_acc: 0.0968\n",
      "Epoch 5/30\n",
      "80/80 [==============================] - 1s 11ms/step - loss: -330.1721 - acc: 0.0958 - val_loss: -387.3577 - val_acc: 0.0968\n",
      "Epoch 6/30\n",
      "80/80 [==============================] - 1s 11ms/step - loss: -410.1954 - acc: 0.0857 - val_loss: -471.4100 - val_acc: 0.0968\n",
      "Epoch 7/30\n",
      "80/80 [==============================] - 1s 11ms/step - loss: -481.6176 - acc: 0.1035 - val_loss: -558.4261 - val_acc: 0.0968\n",
      "Epoch 8/30\n",
      "80/80 [==============================] - 1s 11ms/step - loss: -559.7003 - acc: 0.1053 - val_loss: -647.1417 - val_acc: 0.0968\n",
      "Epoch 9/30\n",
      "80/80 [==============================] - 1s 11ms/step - loss: -659.9797 - acc: 0.0949 - val_loss: -739.7671 - val_acc: 0.0968\n",
      "Epoch 10/30\n",
      "80/80 [==============================] - 1s 11ms/step - loss: -790.2490 - acc: 0.0975 - val_loss: -833.5890 - val_acc: 0.0968\n",
      "Epoch 11/30\n",
      "80/80 [==============================] - 1s 12ms/step - loss: -872.4667 - acc: 0.0917 - val_loss: -931.4921 - val_acc: 0.0968\n",
      "Epoch 12/30\n",
      "80/80 [==============================] - 1s 11ms/step - loss: -958.4217 - acc: 0.0895 - val_loss: -1031.0941 - val_acc: 0.0968\n",
      "Epoch 13/30\n",
      "80/80 [==============================] - 1s 11ms/step - loss: -1059.1993 - acc: 0.0978 - val_loss: -1134.3743 - val_acc: 0.0968\n",
      "Epoch 14/30\n",
      "80/80 [==============================] - 1s 11ms/step - loss: -1148.3881 - acc: 0.1157 - val_loss: -1239.7279 - val_acc: 0.0968\n",
      "Epoch 15/30\n",
      "80/80 [==============================] - 1s 12ms/step - loss: -1265.3698 - acc: 0.1046 - val_loss: -1347.2998 - val_acc: 0.0968\n",
      "Epoch 16/30\n",
      "80/80 [==============================] - 1s 12ms/step - loss: -1391.5382 - acc: 0.1050 - val_loss: -1458.0988 - val_acc: 0.0968\n",
      "Epoch 17/30\n",
      "80/80 [==============================] - 1s 11ms/step - loss: -1404.9246 - acc: 0.1098 - val_loss: -1572.6476 - val_acc: 0.0968\n",
      "Epoch 18/30\n",
      "80/80 [==============================] - 1s 11ms/step - loss: -1556.9302 - acc: 0.1060 - val_loss: -1687.9225 - val_acc: 0.0968\n",
      "Epoch 19/30\n",
      "80/80 [==============================] - 1s 12ms/step - loss: -1770.0708 - acc: 0.0883 - val_loss: -1806.5654 - val_acc: 0.0968\n",
      "Epoch 20/30\n",
      "80/80 [==============================] - 1s 11ms/step - loss: -1833.8939 - acc: 0.0981 - val_loss: -1928.3925 - val_acc: 0.0968\n",
      "Epoch 21/30\n",
      "80/80 [==============================] - 1s 12ms/step - loss: -1935.6530 - acc: 0.1073 - val_loss: -2052.1887 - val_acc: 0.0968\n",
      "Epoch 22/30\n",
      "80/80 [==============================] - 1s 12ms/step - loss: -2088.8323 - acc: 0.0994 - val_loss: -2178.9832 - val_acc: 0.0968\n",
      "Epoch 23/30\n",
      "80/80 [==============================] - 1s 12ms/step - loss: -2276.0663 - acc: 0.0826 - val_loss: -2309.0530 - val_acc: 0.0968\n",
      "Epoch 24/30\n",
      "80/80 [==============================] - 1s 12ms/step - loss: -2356.3224 - acc: 0.1047 - val_loss: -2440.3525 - val_acc: 0.0968\n",
      "Epoch 25/30\n",
      "80/80 [==============================] - 1s 12ms/step - loss: -2471.2702 - acc: 0.0946 - val_loss: -2575.7766 - val_acc: 0.0968\n",
      "Epoch 26/30\n",
      "80/80 [==============================] - 1s 12ms/step - loss: -2614.5741 - acc: 0.1064 - val_loss: -2712.1572 - val_acc: 0.0968\n",
      "Epoch 27/30\n",
      "80/80 [==============================] - 1s 12ms/step - loss: -2783.6199 - acc: 0.0835 - val_loss: -2853.1904 - val_acc: 0.0968\n",
      "Epoch 28/30\n",
      "80/80 [==============================] - 1s 12ms/step - loss: -2936.5349 - acc: 0.0863 - val_loss: -2995.0093 - val_acc: 0.0968\n",
      "Epoch 29/30\n",
      "80/80 [==============================] - 1s 12ms/step - loss: -3009.1080 - acc: 0.1080 - val_loss: -3141.5051 - val_acc: 0.0968\n",
      "Epoch 30/30\n",
      "80/80 [==============================] - 1s 12ms/step - loss: -3162.7308 - acc: 0.0971 - val_loss: -3289.1819 - val_acc: 0.0968\n"
     ]
    }
   ],
   "source": [
    "#train on recorded data/labels:\n",
    "from keras import models\n",
    "from keras import layers\n",
    "from keras import optimizers\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(256, activation='relu', input_dim=4 * 4 * 512))\n",
    "model.add(layers.Dropout(0.5))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(optimizer=optimizers.RMSprop(lr=2e-5),\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['acc'])\n",
    "\n",
    "history = model.fit(train_features, train_labels,\n",
    "                    epochs=30,\n",
    "                    batch_size=20,\n",
    "                    validation_data=(validation_features, validation_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "entitled-submission",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "def benchmark(model):\n",
    "    y_pred = model.predict(x_test)\n",
    "\n",
    "    print(f\"mae: {metrics.mean_absolute_error(y_test, y_pred):,.2f}\")\n",
    "    print(f\"mse: {metrics.mean_squared_error(y_test, y_pred):,.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "covered-mortgage",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #loss and accuracy curves during training;\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# acc = history.history['acc']\n",
    "# val_acc = history.history['val_acc']\n",
    "# loss = history.history['loss']\n",
    "# val_loss = history.history['val_loss']\n",
    "\n",
    "# epochs = range(len(acc))\n",
    "\n",
    "# plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "# plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "# plt.title('Training and validation accuracy')\n",
    "# plt.legend()\n",
    "\n",
    "# plt.figure()\n",
    "\n",
    "# plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "# plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "# plt.title('Training and validation loss')\n",
    "# plt.legend()\n",
    "\n",
    "# plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
