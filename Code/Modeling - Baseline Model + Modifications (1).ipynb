{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "agreed-brand",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mehikapatel/opt/anaconda3/lib/python3.8/site-packages/gensim/similarities/__init__.py:15: UserWarning: The gensim.similarities.levenshtein submodule is disabled, because the optional Levenshtein package <https://pypi.org/project/python-Levenshtein/> is unavailable. Install Levenhstein (e.g. `pip install python-Levenshtein`) to suppress this warning.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "# display and plotting imports\n",
    "%pylab inline \n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "from IPython.display import SVG\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# sklearn imports\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# keras imports\n",
    "from keras.utils import np_utils\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers import Dense, Activation, Dropout\n",
    "from keras.layers import Input, Embedding, Bidirectional, LSTM\n",
    "\n",
    "# gensim import for word2vec loading\n",
    "from gensim.models.keyedvectors import KeyedVectors# display and plotting imports\n",
    "%pylab inline \n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "from IPython.display import SVG\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# sklearn imports\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# keras imports\n",
    "from keras.utils import np_utils\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers import Dense, Activation, Dropout\n",
    "from keras.layers import Input, Embedding, Bidirectional, LSTM\n",
    "\n",
    "# gensim import for word2vec loading\n",
    "from gensim.models.keyedvectors import KeyedVectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "graduate-steel",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "boxed-bristol",
   "metadata": {},
   "source": [
    "## Plant Classification MVP\n",
    "\n",
    "This project involves using neural networks and transfer learning to classify leaves by plant type. There are 11 classes total. \n",
    "\n",
    "This notebook outlines initial modeling. A simple baseline neural network will be built."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ruled-whole",
   "metadata": {},
   "outputs": [],
   "source": [
    "# display and plotting imports\n",
    "%pylab inline \n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "from IPython.display import SVG\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# sklearn imports\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# keras imports\n",
    "from keras.utils import np_utils\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers import Dense, Activation, Dropout\n",
    "from keras.layers import Input, Embedding, Bidirectional, LSTM\n",
    "\n",
    "# gensim import for word2vec loading\n",
    "from gensim.models.keyedvectors import KeyedVectors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fluid-straight",
   "metadata": {},
   "source": [
    "## Image Processing for Baseline Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "juvenile-attempt",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "base_dir = '/Users/mehikapatel/Plant_NN_Project/data'\n",
    "\n",
    "train_dir = os.path.join(base_dir, 'train')\n",
    "validation_dir = os.path.join(base_dir, 'validation')\n",
    "test_dir = os.path.join(base_dir, 'test')\n",
    "\n",
    "datagen = ImageDataGenerator(rescale=1./255)\n",
    "batch_size = 20\n",
    "\n",
    "def extract_features(directory, sample_count):\n",
    "    features = np.zeros(shape=(sample_count, 150, 150, 3))\n",
    "    labels = np.zeros(shape=(sample_count,11))\n",
    "    generator = datagen.flow_from_directory(\n",
    "        directory,\n",
    "        target_size=(150, 150),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical')\n",
    "    i = 0\n",
    "    for inputs_batch, labels_batch in generator:\n",
    "        features[i * batch_size : (i + 1) * batch_size] = inputs_batch\n",
    "        labels[i * batch_size : (i + 1) * batch_size] = labels_batch\n",
    "        i += 1\n",
    "        if i * batch_size >= sample_count:\n",
    "            # Note that since generators yield data indefinitely in a loop,\n",
    "            # we must `break` after every image has been seen once.\n",
    "            break\n",
    "    return features, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "dying-great",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1592 images belonging to 11 classes.\n",
      "Found 341 images belonging to 11 classes.\n",
      "Found 344 images belonging to 11 classes.\n"
     ]
    }
   ],
   "source": [
    "train_features, train_labels = extract_features(train_dir, 1592)\n",
    "validation_features, validation_labels = extract_features(validation_dir, 341) \n",
    "test_features, test_labels = extract_features(test_dir, 344) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "fuzzy-vault",
   "metadata": {},
   "outputs": [],
   "source": [
    "#flatten images:\n",
    "train_features = np.reshape(train_features, (1592, 150 * 150 * 3))\n",
    "validation_features = np.reshape(validation_features, (341, 150 * 150 * 3))\n",
    "test_features = np.reshape(test_features, (344, 150 * 150 * 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "sustainable-attack",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_11\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_65 (Dense)             (None, 5)                 337505    \n",
      "_________________________________________________________________\n",
      "dense_66 (Dense)             (None, 11)                66        \n",
      "=================================================================\n",
      "Total params: 337,571\n",
      "Trainable params: 337,571\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "base = keras.Sequential([\n",
    "    keras.layers.InputLayer(input_shape=train_features.shape[1:]),\n",
    "    keras.layers.Dense(units=5, activation=\"relu\"),\n",
    "    keras.layers.Dense(units=11, activation= \"softmax\"),\n",
    "])\n",
    "\n",
    "base.compile(\"nadam\", loss=\"categorical_crossentropy\", metrics=[\"acc\"])\n",
    "\n",
    "base.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "accredited-coordination",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "50/50 [==============================] - 2s 9ms/step - loss: 2.4024 - acc: 0.1123\n",
      "Epoch 2/100\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 2.3879 - acc: 0.1464\n",
      "Epoch 3/100\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 2.3831 - acc: 0.1236\n",
      "Epoch 4/100\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 2.3761 - acc: 0.1516\n",
      "Epoch 5/100\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 2.3739 - acc: 0.1354\n",
      "Epoch 6/100\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 2.3665 - acc: 0.1493\n",
      "Epoch 7/100\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 2.3676 - acc: 0.1474\n",
      "Epoch 8/100\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 2.3602 - acc: 0.1359\n",
      "Epoch 9/100\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 2.3628 - acc: 0.1237\n",
      "Epoch 10/100\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 2.3585 - acc: 0.1336\n",
      "Epoch 11/100\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 2.3473 - acc: 0.1424\n",
      "Epoch 12/100\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 2.3470 - acc: 0.1390\n",
      "Epoch 13/100\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 2.3625 - acc: 0.1353\n",
      "Epoch 14/100\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 2.3509 - acc: 0.1500\n",
      "Epoch 15/100\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 2.3479 - acc: 0.1338\n",
      "Epoch 16/100\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 2.3480 - acc: 0.1292\n",
      "Epoch 17/100\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 2.3502 - acc: 0.1381\n",
      "Epoch 18/100\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 2.3383 - acc: 0.1530\n",
      "Epoch 19/100\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 2.3490 - acc: 0.1350\n",
      "Epoch 20/100\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 2.3391 - acc: 0.1497\n",
      "Epoch 21/100\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 2.3379 - acc: 0.1427\n",
      "Epoch 22/100\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 2.3471 - acc: 0.1359\n",
      "Epoch 23/100\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 2.3320 - acc: 0.1537\n",
      "Epoch 24/100\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 2.3431 - acc: 0.1441\n",
      "Epoch 25/100\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 2.3507 - acc: 0.1313\n",
      "Epoch 26/100\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 2.3451 - acc: 0.1337\n",
      "Epoch 27/100\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 2.3451 - acc: 0.1485\n",
      "Epoch 28/100\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 2.3395 - acc: 0.1294\n",
      "Epoch 29/100\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 2.3379 - acc: 0.1352\n",
      "Epoch 30/100\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 2.3390 - acc: 0.1323\n",
      "Epoch 31/100\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 2.3494 - acc: 0.1298\n",
      "Epoch 32/100\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 2.3304 - acc: 0.1442\n",
      "Epoch 33/100\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 2.3534 - acc: 0.1290\n",
      "Epoch 34/100\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 2.3296 - acc: 0.1589\n",
      "Epoch 35/100\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 2.3389 - acc: 0.1468\n",
      "Epoch 36/100\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 2.3391 - acc: 0.1385\n",
      "Epoch 37/100\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 2.3350 - acc: 0.1434\n",
      "Epoch 38/100\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 2.3462 - acc: 0.1458\n",
      "Epoch 39/100\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 2.3463 - acc: 0.1456\n",
      "Epoch 40/100\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 2.3502 - acc: 0.1363\n",
      "Epoch 41/100\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 2.3433 - acc: 0.1395\n",
      "Epoch 42/100\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 2.3418 - acc: 0.1323\n",
      "Epoch 43/100\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 2.3609 - acc: 0.1241\n",
      "Epoch 44/100\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 2.3377 - acc: 0.1441\n",
      "Epoch 45/100\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 2.3391 - acc: 0.1371\n",
      "Epoch 46/100\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 2.3301 - acc: 0.1593\n",
      "Epoch 47/100\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 2.3551 - acc: 0.1314\n",
      "Epoch 48/100\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 2.3286 - acc: 0.1397\n",
      "Epoch 49/100\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 2.3327 - acc: 0.1438\n",
      "Epoch 50/100\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 2.3329 - acc: 0.1519\n",
      "Epoch 51/100\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 2.3495 - acc: 0.1339\n",
      "Epoch 52/100\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 2.3389 - acc: 0.1516\n",
      "Epoch 53/100\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 2.3498 - acc: 0.1444\n",
      "Epoch 54/100\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 2.3439 - acc: 0.1356\n",
      "Epoch 55/100\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 2.3363 - acc: 0.1583\n",
      "Epoch 56/100\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 2.3357 - acc: 0.1439\n",
      "Epoch 57/100\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 2.3412 - acc: 0.1398\n",
      "Epoch 58/100\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 2.3357 - acc: 0.1539\n",
      "Epoch 59/100\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 2.3395 - acc: 0.1354\n",
      "Epoch 60/100\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 2.3388 - acc: 0.1524\n",
      "Epoch 61/100\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 2.3434 - acc: 0.1389\n",
      "Epoch 62/100\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 2.3344 - acc: 0.1418\n",
      "Epoch 63/100\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 2.3485 - acc: 0.1457\n",
      "Epoch 64/100\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 2.3475 - acc: 0.1385\n",
      "Epoch 65/100\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 2.3398 - acc: 0.1400\n",
      "Epoch 66/100\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 2.3467 - acc: 0.1425\n",
      "Epoch 67/100\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 2.3429 - acc: 0.1443\n",
      "Epoch 68/100\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 2.3477 - acc: 0.1379\n",
      "Epoch 69/100\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 2.3327 - acc: 0.1537\n",
      "Epoch 70/100\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 2.3485 - acc: 0.1385\n",
      "Epoch 71/100\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 2.3385 - acc: 0.1447\n",
      "Epoch 72/100\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 2.3446 - acc: 0.1326\n",
      "Epoch 73/100\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 2.3426 - acc: 0.1271\n",
      "Epoch 74/100\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 2.3379 - acc: 0.1474\n",
      "Epoch 75/100\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 2.3275 - acc: 0.1437\n",
      "Epoch 76/100\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 2.3340 - acc: 0.1376\n",
      "Epoch 77/100\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 2.3426 - acc: 0.1385\n",
      "Epoch 78/100\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 2.3377 - acc: 0.1473\n",
      "Epoch 79/100\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 2.3480 - acc: 0.1289\n",
      "Epoch 80/100\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 2.3396 - acc: 0.1495\n",
      "Epoch 81/100\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 2.3490 - acc: 0.1320\n",
      "Epoch 82/100\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 2.3504 - acc: 0.1406\n",
      "Epoch 83/100\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 2.3406 - acc: 0.1426\n",
      "Epoch 84/100\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 2.3461 - acc: 0.1525\n",
      "Epoch 85/100\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 2.3438 - acc: 0.1267\n",
      "Epoch 86/100\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 2.3303 - acc: 0.1356\n",
      "Epoch 87/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50/50 [==============================] - 0s 6ms/step - loss: 2.3358 - acc: 0.1415\n",
      "Epoch 88/100\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 2.3355 - acc: 0.1378\n",
      "Epoch 89/100\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 2.3436 - acc: 0.1322\n",
      "Epoch 90/100\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 2.3424 - acc: 0.1449\n",
      "Epoch 91/100\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 2.3339 - acc: 0.1523\n",
      "Epoch 92/100\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 2.3309 - acc: 0.1386\n",
      "Epoch 93/100\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 2.3314 - acc: 0.1460\n",
      "Epoch 94/100\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 2.3529 - acc: 0.1362\n",
      "Epoch 95/100\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 2.3364 - acc: 0.1359\n",
      "Epoch 96/100\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 2.3303 - acc: 0.1454\n",
      "Epoch 97/100\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 2.3436 - acc: 0.1461\n",
      "Epoch 98/100\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 2.3450 - acc: 0.1462\n",
      "Epoch 99/100\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 2.3331 - acc: 0.1391\n",
      "Epoch 100/100\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 2.3413 - acc: 0.1412\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fd7f8b06c40>"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base.fit(train_features, train_labels, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "known-tournament",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 4ms/step - loss: 2.3388 - acc: 0.1408\n",
      "\n",
      "\n",
      "Validation Accuracy: 0.14076246321201324\n"
     ]
    }
   ],
   "source": [
    "val_loss, val_acc = base.evaluate(validation_features, validation_labels)\n",
    "print(f'\\n\\nValidation Accuracy: {val_acc}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "genetic-congress",
   "metadata": {},
   "source": [
    "## Let's try adding more layers to the base model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "played-financing",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_12\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_67 (Dense)             (None, 300)               20250300  \n",
      "_________________________________________________________________\n",
      "dense_68 (Dense)             (None, 250)               75250     \n",
      "_________________________________________________________________\n",
      "dense_69 (Dense)             (None, 200)               50200     \n",
      "_________________________________________________________________\n",
      "dense_70 (Dense)             (None, 150)               30150     \n",
      "_________________________________________________________________\n",
      "dense_71 (Dense)             (None, 100)               15100     \n",
      "_________________________________________________________________\n",
      "dense_72 (Dense)             (None, 50)                5050      \n",
      "_________________________________________________________________\n",
      "dense_73 (Dense)             (None, 11)                561       \n",
      "=================================================================\n",
      "Total params: 20,426,611\n",
      "Trainable params: 20,426,611\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "bigger = keras.Sequential([\n",
    "    keras.layers.InputLayer(input_shape=train_features.shape[1:]),\n",
    "    keras.layers.Dense(units=300, activation=\"relu\"),\n",
    "    keras.layers.Dense(units=250, activation=\"relu\"),\n",
    "    keras.layers.Dense(units=200, activation=\"relu\"),\n",
    "    keras.layers.Dense(units=150, activation=\"relu\"),\n",
    "    keras.layers.Dense(units=100, activation=\"relu\"),\n",
    "    keras.layers.Dense(units=50, activation=\"relu\"),\n",
    "    keras.layers.Dense(units=11, activation= \"softmax\"),\n",
    "])\n",
    "\n",
    "bigger.compile(\"nadam\", loss=\"categorical_crossentropy\", metrics=[\"acc\"])\n",
    "\n",
    "bigger.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "amber-grammar",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "50/50 [==============================] - 18s 292ms/step - loss: 3.7935 - acc: 0.0964\n",
      "Epoch 2/100\n",
      "50/50 [==============================] - 14s 274ms/step - loss: 2.2839 - acc: 0.1665\n",
      "Epoch 3/100\n",
      "50/50 [==============================] - 13s 252ms/step - loss: 2.1543 - acc: 0.2599\n",
      "Epoch 4/100\n",
      "50/50 [==============================] - 13s 257ms/step - loss: 2.0036 - acc: 0.3069\n",
      "Epoch 5/100\n",
      "50/50 [==============================] - 13s 254ms/step - loss: 2.1220 - acc: 0.2781\n",
      "Epoch 6/100\n",
      "50/50 [==============================] - 13s 253ms/step - loss: 1.8868 - acc: 0.3412\n",
      "Epoch 7/100\n",
      "50/50 [==============================] - 13s 254ms/step - loss: 1.6885 - acc: 0.4312\n",
      "Epoch 8/100\n",
      "50/50 [==============================] - 13s 253ms/step - loss: 1.4918 - acc: 0.4588\n",
      "Epoch 9/100\n",
      "50/50 [==============================] - 13s 259ms/step - loss: 1.4869 - acc: 0.4775\n",
      "Epoch 10/100\n",
      "50/50 [==============================] - 13s 256ms/step - loss: 1.3568 - acc: 0.5370\n",
      "Epoch 11/100\n",
      "50/50 [==============================] - 13s 253ms/step - loss: 1.2543 - acc: 0.5712\n",
      "Epoch 12/100\n",
      "50/50 [==============================] - 13s 254ms/step - loss: 1.2390 - acc: 0.5711\n",
      "Epoch 13/100\n",
      "50/50 [==============================] - 13s 257ms/step - loss: 1.0388 - acc: 0.6524\n",
      "Epoch 14/100\n",
      "50/50 [==============================] - 13s 266ms/step - loss: 0.9791 - acc: 0.6767\n",
      "Epoch 15/100\n",
      "50/50 [==============================] - 13s 254ms/step - loss: 0.9188 - acc: 0.6962\n",
      "Epoch 16/100\n",
      "50/50 [==============================] - 13s 255ms/step - loss: 0.9750 - acc: 0.6857\n",
      "Epoch 17/100\n",
      "50/50 [==============================] - 13s 255ms/step - loss: 0.7644 - acc: 0.7373\n",
      "Epoch 18/100\n",
      "50/50 [==============================] - 13s 254ms/step - loss: 0.8881 - acc: 0.7226\n",
      "Epoch 19/100\n",
      "50/50 [==============================] - 13s 257ms/step - loss: 0.9462 - acc: 0.7059\n",
      "Epoch 20/100\n",
      "50/50 [==============================] - 13s 256ms/step - loss: 0.7504 - acc: 0.7701\n",
      "Epoch 21/100\n",
      "50/50 [==============================] - 14s 285ms/step - loss: 0.7083 - acc: 0.7665\n",
      "Epoch 22/100\n",
      "50/50 [==============================] - 13s 257ms/step - loss: 0.6159 - acc: 0.7999\n",
      "Epoch 23/100\n",
      "50/50 [==============================] - 13s 253ms/step - loss: 0.5789 - acc: 0.8142\n",
      "Epoch 24/100\n",
      "50/50 [==============================] - 13s 252ms/step - loss: 1.0751 - acc: 0.6616\n",
      "Epoch 25/100\n",
      "50/50 [==============================] - 13s 252ms/step - loss: 0.6690 - acc: 0.7804\n",
      "Epoch 26/100\n",
      "50/50 [==============================] - 13s 252ms/step - loss: 0.5574 - acc: 0.8045\n",
      "Epoch 27/100\n",
      "50/50 [==============================] - 13s 252ms/step - loss: 0.4974 - acc: 0.8401\n",
      "Epoch 28/100\n",
      "50/50 [==============================] - 13s 253ms/step - loss: 0.7624 - acc: 0.7966\n",
      "Epoch 29/100\n",
      "50/50 [==============================] - 13s 257ms/step - loss: 0.9954 - acc: 0.6678\n",
      "Epoch 30/100\n",
      "50/50 [==============================] - 13s 256ms/step - loss: 0.7602 - acc: 0.7466\n",
      "Epoch 31/100\n",
      "50/50 [==============================] - 13s 254ms/step - loss: 0.5863 - acc: 0.8063\n",
      "Epoch 32/100\n",
      "50/50 [==============================] - 13s 254ms/step - loss: 0.4545 - acc: 0.8486\n",
      "Epoch 33/100\n",
      "50/50 [==============================] - 13s 256ms/step - loss: 0.4684 - acc: 0.8429\n",
      "Epoch 34/100\n",
      "50/50 [==============================] - 13s 263ms/step - loss: 0.3789 - acc: 0.8740\n",
      "Epoch 35/100\n",
      "50/50 [==============================] - 13s 253ms/step - loss: 0.4462 - acc: 0.8477\n",
      "Epoch 36/100\n",
      "50/50 [==============================] - 13s 251ms/step - loss: 0.3798 - acc: 0.8757\n",
      "Epoch 37/100\n",
      "50/50 [==============================] - 13s 253ms/step - loss: 0.3486 - acc: 0.8963\n",
      "Epoch 38/100\n",
      "50/50 [==============================] - 13s 253ms/step - loss: 0.2614 - acc: 0.9206\n",
      "Epoch 39/100\n",
      "50/50 [==============================] - 13s 251ms/step - loss: 0.2530 - acc: 0.9197\n",
      "Epoch 40/100\n",
      "50/50 [==============================] - 13s 254ms/step - loss: 0.3002 - acc: 0.9024\n",
      "Epoch 41/100\n",
      "50/50 [==============================] - 13s 253ms/step - loss: 0.4655 - acc: 0.8715\n",
      "Epoch 42/100\n",
      "50/50 [==============================] - 13s 252ms/step - loss: 0.2343 - acc: 0.9178\n",
      "Epoch 43/100\n",
      "50/50 [==============================] - 13s 252ms/step - loss: 0.3012 - acc: 0.9041\n",
      "Epoch 44/100\n",
      "50/50 [==============================] - 13s 254ms/step - loss: 0.1611 - acc: 0.9536\n",
      "Epoch 45/100\n",
      "50/50 [==============================] - 13s 253ms/step - loss: 0.3456 - acc: 0.8903\n",
      "Epoch 46/100\n",
      "50/50 [==============================] - 13s 260ms/step - loss: 0.2163 - acc: 0.9446\n",
      "Epoch 47/100\n",
      "50/50 [==============================] - 13s 257ms/step - loss: 0.2357 - acc: 0.9399\n",
      "Epoch 48/100\n",
      "50/50 [==============================] - 13s 256ms/step - loss: 0.1853 - acc: 0.9363\n",
      "Epoch 49/100\n",
      "50/50 [==============================] - 13s 252ms/step - loss: 0.1867 - acc: 0.9415\n",
      "Epoch 50/100\n",
      "50/50 [==============================] - 13s 252ms/step - loss: 0.1312 - acc: 0.9620\n",
      "Epoch 51/100\n",
      "50/50 [==============================] - 13s 254ms/step - loss: 0.1665 - acc: 0.9474\n",
      "Epoch 52/100\n",
      "50/50 [==============================] - 13s 253ms/step - loss: 0.1359 - acc: 0.9585\n",
      "Epoch 53/100\n",
      "50/50 [==============================] - 16s 316ms/step - loss: 0.2867 - acc: 0.9149\n",
      "Epoch 54/100\n",
      "50/50 [==============================] - 16s 323ms/step - loss: 0.6058 - acc: 0.8077\n",
      "Epoch 55/100\n",
      "50/50 [==============================] - 16s 324ms/step - loss: 0.2282 - acc: 0.9364\n",
      "Epoch 56/100\n",
      "50/50 [==============================] - 13s 260ms/step - loss: 0.0836 - acc: 0.9805\n",
      "Epoch 57/100\n",
      "50/50 [==============================] - 13s 254ms/step - loss: 0.1603 - acc: 0.9533\n",
      "Epoch 58/100\n",
      "50/50 [==============================] - 13s 252ms/step - loss: 0.2030 - acc: 0.9373\n",
      "Epoch 59/100\n",
      "50/50 [==============================] - 13s 251ms/step - loss: 0.0899 - acc: 0.9709\n",
      "Epoch 60/100\n",
      "50/50 [==============================] - 13s 252ms/step - loss: 0.0772 - acc: 0.9764\n",
      "Epoch 61/100\n",
      "50/50 [==============================] - 13s 252ms/step - loss: 0.0841 - acc: 0.9752\n",
      "Epoch 62/100\n",
      "50/50 [==============================] - 13s 252ms/step - loss: 0.4549 - acc: 0.8954\n",
      "Epoch 63/100\n",
      "50/50 [==============================] - 13s 255ms/step - loss: 0.9086 - acc: 0.7042\n",
      "Epoch 64/100\n",
      "50/50 [==============================] - 13s 252ms/step - loss: 0.2743 - acc: 0.9184\n",
      "Epoch 65/100\n",
      "50/50 [==============================] - 13s 253ms/step - loss: 0.2209 - acc: 0.9295\n",
      "Epoch 66/100\n",
      "50/50 [==============================] - 13s 253ms/step - loss: 0.1256 - acc: 0.9606\n",
      "Epoch 67/100\n",
      "50/50 [==============================] - 13s 260ms/step - loss: 0.0915 - acc: 0.9730\n",
      "Epoch 68/100\n",
      "50/50 [==============================] - 13s 255ms/step - loss: 0.3263 - acc: 0.9222\n",
      "Epoch 69/100\n",
      "50/50 [==============================] - 13s 253ms/step - loss: 0.3463 - acc: 0.8937\n",
      "Epoch 70/100\n",
      "50/50 [==============================] - 13s 256ms/step - loss: 0.1641 - acc: 0.9507\n",
      "Epoch 71/100\n",
      "50/50 [==============================] - 13s 254ms/step - loss: 0.0914 - acc: 0.9699\n",
      "Epoch 72/100\n",
      "50/50 [==============================] - 13s 253ms/step - loss: 0.0718 - acc: 0.9781\n",
      "Epoch 73/100\n",
      "50/50 [==============================] - 13s 252ms/step - loss: 1.1850 - acc: 0.7598\n",
      "Epoch 74/100\n",
      "50/50 [==============================] - 13s 253ms/step - loss: 0.2074 - acc: 0.9272\n",
      "Epoch 75/100\n",
      "50/50 [==============================] - 13s 252ms/step - loss: 0.1169 - acc: 0.9594\n",
      "Epoch 76/100\n",
      "50/50 [==============================] - 13s 253ms/step - loss: 0.0934 - acc: 0.9753\n",
      "Epoch 77/100\n",
      "50/50 [==============================] - 13s 254ms/step - loss: 0.0528 - acc: 0.9847\n",
      "Epoch 78/100\n",
      "50/50 [==============================] - 13s 256ms/step - loss: 0.0512 - acc: 0.9819\n",
      "Epoch 79/100\n",
      "50/50 [==============================] - 13s 257ms/step - loss: 0.1755 - acc: 0.9503\n",
      "Epoch 80/100\n",
      "50/50 [==============================] - 13s 256ms/step - loss: 0.0978 - acc: 0.9724\n",
      "Epoch 81/100\n",
      "50/50 [==============================] - 13s 255ms/step - loss: 0.0549 - acc: 0.9834\n",
      "Epoch 82/100\n",
      "50/50 [==============================] - 13s 254ms/step - loss: 0.0621 - acc: 0.9833\n",
      "Epoch 83/100\n",
      "50/50 [==============================] - 13s 255ms/step - loss: 0.0271 - acc: 0.9924\n",
      "Epoch 84/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50/50 [==============================] - 13s 266ms/step - loss: 0.0185 - acc: 0.9968\n",
      "Epoch 85/100\n",
      "50/50 [==============================] - 12s 250ms/step - loss: 0.0265 - acc: 0.9937\n",
      "Epoch 86/100\n",
      "50/50 [==============================] - 13s 252ms/step - loss: 0.0176 - acc: 0.9960\n",
      "Epoch 87/100\n",
      "50/50 [==============================] - 13s 251ms/step - loss: 0.0185 - acc: 0.9960\n",
      "Epoch 88/100\n",
      "50/50 [==============================] - 12s 249ms/step - loss: 0.0071 - acc: 0.9991\n",
      "Epoch 89/100\n",
      "50/50 [==============================] - 12s 249ms/step - loss: 0.3034 - acc: 0.9659\n",
      "Epoch 90/100\n",
      "50/50 [==============================] - 12s 249ms/step - loss: 1.6768 - acc: 0.3981\n",
      "Epoch 91/100\n",
      "50/50 [==============================] - 13s 257ms/step - loss: 0.8784 - acc: 0.7150\n",
      "Epoch 92/100\n",
      "50/50 [==============================] - 12s 249ms/step - loss: 0.4882 - acc: 0.8538\n",
      "Epoch 93/100\n",
      "50/50 [==============================] - 13s 250ms/step - loss: 0.3795 - acc: 0.8846\n",
      "Epoch 94/100\n",
      "50/50 [==============================] - 13s 251ms/step - loss: 0.2569 - acc: 0.9193\n",
      "Epoch 95/100\n",
      "50/50 [==============================] - 12s 248ms/step - loss: 0.1845 - acc: 0.9453\n",
      "Epoch 96/100\n",
      "50/50 [==============================] - 13s 251ms/step - loss: 0.1958 - acc: 0.9355\n",
      "Epoch 97/100\n",
      "50/50 [==============================] - 12s 247ms/step - loss: 0.1384 - acc: 0.9632\n",
      "Epoch 98/100\n",
      "50/50 [==============================] - 12s 248ms/step - loss: 0.1333 - acc: 0.9626\n",
      "Epoch 99/100\n",
      "50/50 [==============================] - 13s 250ms/step - loss: 0.1009 - acc: 0.9712\n",
      "Epoch 100/100\n",
      "50/50 [==============================] - 13s 251ms/step - loss: 0.1206 - acc: 0.9683\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fd745d6b7c0>"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigger.fit(train_features, train_labels, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "headed-might",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 5ms/step - loss: 2.3388 - acc: 0.1408\n",
      "\n",
      "\n",
      "Validation Accuracy: 0.14076246321201324\n"
     ]
    }
   ],
   "source": [
    "val_loss, val_acc = base.evaluate(validation_features, validation_labels)\n",
    "print(f'\\n\\nValidation Accuracy: {val_acc}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "continental-absence",
   "metadata": {},
   "source": [
    "## Image Processing for TL Convolutional Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "sharing-charter",
   "metadata": {},
   "outputs": [],
   "source": [
    "#transfer learning model\n",
    "from tensorflow import keras\n",
    "from keras.applications.vgg16 import VGG16\n",
    "\n",
    "conv_base = VGG16(weights='imagenet',\n",
    "                  include_top=False)\n",
    "import os\n",
    "import numpy as np\n",
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "conditional-danger",
   "metadata": {},
   "outputs": [],
   "source": [
    "#benchmark function\n",
    "from sklearn import metrics\n",
    "def benchmark(model):\n",
    "    y_pred = model.predict(test_features)\n",
    "    print(f\"accuracy: {metrics.accuracy_score(test_labels, y_pred):,.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "human-dubai",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "base_dir = '/Users/mehikapatel/Plant_NN_Project/data'\n",
    "\n",
    "train_dir = os.path.join(base_dir, 'train')\n",
    "validation_dir = os.path.join(base_dir, 'validation')\n",
    "test_dir = os.path.join(base_dir, 'test')\n",
    "\n",
    "datagen = ImageDataGenerator(rescale=1./255)\n",
    "batch_size = 20\n",
    "\n",
    "def extract_features(directory, sample_count):\n",
    "    features = np.zeros(shape=(sample_count, 4, 4, 512))\n",
    "    labels = np.zeros(shape=(sample_count,11))\n",
    "    generator = datagen.flow_from_directory(\n",
    "        directory,\n",
    "        target_size=(150, 150),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical')\n",
    "    i = 0\n",
    "    for inputs_batch, labels_batch in generator:\n",
    "        features_batch = conv_base.predict(inputs_batch)\n",
    "        features[i * batch_size : (i + 1) * batch_size] = features_batch\n",
    "        labels[i * batch_size : (i + 1) * batch_size] = labels_batch\n",
    "        i += 1\n",
    "        if i * batch_size >= sample_count:\n",
    "            # Note that since generators yield data indefinitely in a loop,\n",
    "            # we must `break` after every image has been seen once.\n",
    "            break\n",
    "    return features, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "architectural-romance",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1592 images belonging to 11 classes.\n",
      "Found 341 images belonging to 11 classes.\n",
      "Found 344 images belonging to 11 classes.\n"
     ]
    }
   ],
   "source": [
    "train_features, train_labels = extract_features(train_dir, 1592)\n",
    "validation_features, validation_labels = extract_features(validation_dir, 341) \n",
    "test_features, test_labels = extract_features(test_dir, 344) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "spread-river",
   "metadata": {},
   "outputs": [],
   "source": [
    "#flatten images:\n",
    "train_features = np.reshape(train_features, (1592, 4 * 4 * 512))\n",
    "validation_features = np.reshape(validation_features, (341, 4 * 4 * 512))\n",
    "test_features = np.reshape(test_features, (344, 4 * 4 * 512))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "common-orlando",
   "metadata": {},
   "source": [
    "## Baseline Conv NN Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "minus-relationship",
   "metadata": {},
   "source": [
    "### Fit our first baseline conv model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "straight-rendering",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_3 (Dense)              (None, 5)                 40965     \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 11)                66        \n",
      "=================================================================\n",
      "Total params: 41,031\n",
      "Trainable params: 41,031\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "ff_model = keras.Sequential([\n",
    "    keras.layers.InputLayer(input_shape=train_features.shape[1:]),\n",
    "    keras.layers.Dense(units=5, activation=\"relu\"),\n",
    "    keras.layers.Dense(units=11, activation= \"softmax\"),\n",
    "])\n",
    "\n",
    "ff_model.compile(\"nadam\", loss=\"categorical_crossentropy\", metrics=[\"acc\"])\n",
    "\n",
    "ff_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "small-welsh",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 0.9709 - acc: 0.7104\n",
      "Epoch 2/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.9492 - acc: 0.7217\n",
      "Epoch 3/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.9352 - acc: 0.7173\n",
      "Epoch 4/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.9052 - acc: 0.7544\n",
      "Epoch 5/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.8888 - acc: 0.7557\n",
      "Epoch 6/100\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 0.8834 - acc: 0.7582\n",
      "Epoch 7/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.8649 - acc: 0.7663\n",
      "Epoch 8/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.8484 - acc: 0.7789\n",
      "Epoch 9/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.8321 - acc: 0.7871\n",
      "Epoch 10/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.8275 - acc: 0.7789\n",
      "Epoch 11/100\n",
      "50/50 [==============================] - 0s 5ms/step - loss: 0.8093 - acc: 0.7940\n",
      "Epoch 12/100\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 0.7917 - acc: 0.8034\n",
      "Epoch 13/100\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 0.7801 - acc: 0.8053\n",
      "Epoch 14/100\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 0.7689 - acc: 0.7984\n",
      "Epoch 15/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.7585 - acc: 0.8090\n",
      "Epoch 16/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.7413 - acc: 0.8210\n",
      "Epoch 17/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.7257 - acc: 0.8310\n",
      "Epoch 18/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.7106 - acc: 0.8392\n",
      "Epoch 19/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.7040 - acc: 0.8310\n",
      "Epoch 20/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.6883 - acc: 0.8411\n",
      "Epoch 21/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.6776 - acc: 0.8386\n",
      "Epoch 22/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.6653 - acc: 0.8480\n",
      "Epoch 23/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.6709 - acc: 0.8405\n",
      "Epoch 24/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.6436 - acc: 0.8599\n",
      "Epoch 25/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.6360 - acc: 0.8649\n",
      "Epoch 26/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.6282 - acc: 0.8649\n",
      "Epoch 27/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.6159 - acc: 0.8687\n",
      "Epoch 28/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.5979 - acc: 0.8731\n",
      "Epoch 29/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.5930 - acc: 0.8769\n",
      "Epoch 30/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.5848 - acc: 0.8731\n",
      "Epoch 31/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.5735 - acc: 0.8838\n",
      "Epoch 32/100\n",
      "50/50 [==============================] - 0s 5ms/step - loss: 0.5637 - acc: 0.8951\n",
      "Epoch 33/100\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.5514 - acc: 0.8951\n",
      "Epoch 34/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.5539 - acc: 0.8995\n",
      "Epoch 35/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.5395 - acc: 0.9052\n",
      "Epoch 36/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.5304 - acc: 0.9083\n",
      "Epoch 37/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.5180 - acc: 0.9152\n",
      "Epoch 38/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.5151 - acc: 0.9209\n",
      "Epoch 39/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.5017 - acc: 0.9227\n",
      "Epoch 40/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.4948 - acc: 0.9196\n",
      "Epoch 41/100\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.4863 - acc: 0.9271\n",
      "Epoch 42/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.4797 - acc: 0.9328\n",
      "Epoch 43/100\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.4711 - acc: 0.9296\n",
      "Epoch 44/100\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 0.4603 - acc: 0.9403\n",
      "Epoch 45/100\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.4655 - acc: 0.9240\n",
      "Epoch 46/100\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 0.4473 - acc: 0.9391\n",
      "Epoch 47/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.4526 - acc: 0.9315\n",
      "Epoch 48/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.4354 - acc: 0.9447\n",
      "Epoch 49/100\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 0.4324 - acc: 0.9410\n",
      "Epoch 50/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.4220 - acc: 0.9435\n",
      "Epoch 51/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.4142 - acc: 0.9472\n",
      "Epoch 52/100\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.4103 - acc: 0.9479\n",
      "Epoch 53/100\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 0.4064 - acc: 0.9485\n",
      "Epoch 54/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.4011 - acc: 0.9460\n",
      "Epoch 55/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.3949 - acc: 0.9485\n",
      "Epoch 56/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.3859 - acc: 0.9460\n",
      "Epoch 57/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.3829 - acc: 0.9497\n",
      "Epoch 58/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.3784 - acc: 0.9485\n",
      "Epoch 59/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.3734 - acc: 0.9510\n",
      "Epoch 60/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.3677 - acc: 0.9554\n",
      "Epoch 61/100\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.3600 - acc: 0.9554\n",
      "Epoch 62/100\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 0.3534 - acc: 0.9585\n",
      "Epoch 63/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.3522 - acc: 0.9560\n",
      "Epoch 64/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.3465 - acc: 0.9567\n",
      "Epoch 65/100\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.3396 - acc: 0.9579\n",
      "Epoch 66/100\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 0.3360 - acc: 0.9573\n",
      "Epoch 67/100\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 0.3349 - acc: 0.9560\n",
      "Epoch 68/100\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 0.3275 - acc: 0.9585\n",
      "Epoch 69/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.3277 - acc: 0.9579\n",
      "Epoch 70/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.3184 - acc: 0.9598\n",
      "Epoch 71/100\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 0.3162 - acc: 0.9617\n",
      "Epoch 72/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.3091 - acc: 0.9629\n",
      "Epoch 73/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.3055 - acc: 0.9623\n",
      "Epoch 74/100\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 0.3036 - acc: 0.9661\n",
      "Epoch 75/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.2995 - acc: 0.9680\n",
      "Epoch 76/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.2944 - acc: 0.9629\n",
      "Epoch 77/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.2916 - acc: 0.9648\n",
      "Epoch 78/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.2859 - acc: 0.9661\n",
      "Epoch 79/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.2825 - acc: 0.9648\n",
      "Epoch 80/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.2829 - acc: 0.9661\n",
      "Epoch 81/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.2770 - acc: 0.9673\n",
      "Epoch 82/100\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 0.2732 - acc: 0.9667\n",
      "Epoch 83/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.2722 - acc: 0.9686\n",
      "Epoch 84/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.2663 - acc: 0.9680\n",
      "Epoch 85/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.2679 - acc: 0.9655\n",
      "Epoch 86/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.2604 - acc: 0.9717\n",
      "Epoch 87/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50/50 [==============================] - 0s 2ms/step - loss: 0.2553 - acc: 0.9711\n",
      "Epoch 88/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.2544 - acc: 0.9730\n",
      "Epoch 89/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.2510 - acc: 0.9692\n",
      "Epoch 90/100\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 0.2506 - acc: 0.9724\n",
      "Epoch 91/100\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 0.2463 - acc: 0.9705\n",
      "Epoch 92/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.2405 - acc: 0.9698\n",
      "Epoch 93/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.2387 - acc: 0.9730\n",
      "Epoch 94/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.2380 - acc: 0.9717\n",
      "Epoch 95/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.2332 - acc: 0.9749\n",
      "Epoch 96/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.2278 - acc: 0.9742\n",
      "Epoch 97/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.2356 - acc: 0.9705\n",
      "Epoch 98/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.2257 - acc: 0.9742\n",
      "Epoch 99/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.2215 - acc: 0.9761\n",
      "Epoch 100/100\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.2271 - acc: 0.9736\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fd7cfb955e0>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ff_model.fit(train_features, train_labels, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "following-validation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 2ms/step - loss: 2.6376 - acc: 0.2082\n",
      "\n",
      "\n",
      "Validation Accuracy: 0.20821113884449005\n"
     ]
    }
   ],
   "source": [
    "val_loss, val_acc = ff_model.evaluate(validation_features, validation_labels)\n",
    "print(f'\\n\\nValidation Accuracy: {val_acc}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "front-handling",
   "metadata": {},
   "source": [
    "### We will need a lot of modifications to improve this model on our validation data!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "palestinian-china",
   "metadata": {},
   "source": [
    "## Modified Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "accepted-equivalent",
   "metadata": {},
   "source": [
    "**More Layers & Nodes**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "governing-cattle",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_13\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_75 (Dense)             (None, 150)               10125150  \n",
      "_________________________________________________________________\n",
      "dense_76 (Dense)             (None, 125)               18875     \n",
      "_________________________________________________________________\n",
      "dense_77 (Dense)             (None, 100)               12600     \n",
      "_________________________________________________________________\n",
      "dense_78 (Dense)             (None, 75)                7575      \n",
      "_________________________________________________________________\n",
      "dense_79 (Dense)             (None, 50)                3800      \n",
      "_________________________________________________________________\n",
      "dense_80 (Dense)             (None, 25)                1275      \n",
      "_________________________________________________________________\n",
      "dense_81 (Dense)             (None, 11)                286       \n",
      "=================================================================\n",
      "Total params: 10,169,561\n",
      "Trainable params: 10,169,561\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "base_model = keras.Sequential([\n",
    "    keras.layers.InputLayer(input_shape=train_features.shape[1:]),\n",
    "    keras.layers.Dense(units=150, activation=\"relu\"),\n",
    "    keras.layers.Dense(units=125, activation=\"relu\"),\n",
    "    keras.layers.Dense(units=100, activation=\"relu\"),\n",
    "    keras.layers.Dense(units=75, activation=\"relu\"),\n",
    "    keras.layers.Dense(units=50, activation=\"relu\"),\n",
    "    keras.layers.Dense(units=25, activation=\"relu\"),\n",
    "    keras.layers.Dense(units=11, activation= \"softmax\"),\n",
    "])\n",
    "\n",
    "base_model.compile(\"nadam\", loss=\"categorical_crossentropy\", metrics=[\"acc\"])\n",
    "\n",
    "base_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "negative-honey",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "50/50 [==============================] - 10s 148ms/step - loss: 2.8971 - acc: 0.1125\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,acc\n",
      "Epoch 2/100\n",
      "50/50 [==============================] - 9s 173ms/step - loss: 2.3068 - acc: 0.1779\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,acc\n",
      "Epoch 3/100\n",
      "50/50 [==============================] - 6s 108ms/step - loss: 2.2817 - acc: 0.1666\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,acc\n",
      "Epoch 4/100\n",
      "50/50 [==============================] - 6s 111ms/step - loss: 2.2637 - acc: 0.1694\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,acc\n",
      "Epoch 5/100\n",
      "50/50 [==============================] - 6s 111ms/step - loss: 2.3900 - acc: 0.1184\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,acc\n",
      "Epoch 6/100\n",
      "50/50 [==============================] - 6s 125ms/step - loss: 2.3827 - acc: 0.1198\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,acc\n",
      "Epoch 7/100\n",
      "50/50 [==============================] - 8s 155ms/step - loss: 2.3782 - acc: 0.1097\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,acc\n",
      "Epoch 8/100\n",
      "50/50 [==============================] - 6s 122ms/step - loss: 2.3705 - acc: 0.1347\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,acc\n",
      "Epoch 9/100\n",
      "50/50 [==============================] - 7s 133ms/step - loss: 2.3679 - acc: 0.1448\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,acc\n",
      "Epoch 10/100\n",
      "50/50 [==============================] - 5s 105ms/step - loss: 2.3668 - acc: 0.1415\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,acc\n",
      "Epoch 11/100\n",
      "50/50 [==============================] - 5s 101ms/step - loss: 2.3632 - acc: 0.1405\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,acc\n",
      "Epoch 12/100\n",
      "50/50 [==============================] - 5s 97ms/step - loss: 2.3551 - acc: 0.1418\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,acc\n",
      "Epoch 13/100\n",
      "50/50 [==============================] - 5s 97ms/step - loss: 2.3565 - acc: 0.1384\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,acc\n",
      "Epoch 14/100\n",
      "50/50 [==============================] - 5s 96ms/step - loss: 2.3512 - acc: 0.1409\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,acc\n",
      "Epoch 15/100\n",
      "50/50 [==============================] - 5s 97ms/step - loss: 2.3459 - acc: 0.1471\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,acc\n",
      "Epoch 16/100\n",
      "50/50 [==============================] - 5s 101ms/step - loss: 2.3459 - acc: 0.1335\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,acc\n",
      "Epoch 17/100\n",
      "50/50 [==============================] - 5s 99ms/step - loss: 2.3471 - acc: 0.1373\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,acc\n",
      "Epoch 18/100\n",
      "50/50 [==============================] - 6s 117ms/step - loss: 2.3449 - acc: 0.1344\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,acc\n",
      "Epoch 19/100\n",
      "50/50 [==============================] - 6s 122ms/step - loss: 2.3378 - acc: 0.1366\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,acc\n",
      "Epoch 20/100\n",
      "49/50 [============================>.] - ETA: 0s - loss: 2.3444 - acc: 0.1430"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-151-965af4a0a95e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m base_model.fit(train_features, train_labels, epochs=100,callbacks=[\n\u001b[0m\u001b[1;32m      2\u001b[0m         \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEarlyStopping\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpatience\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrestore_best_weights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     ])\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1161\u001b[0m               \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtmp_logs\u001b[0m  \u001b[0;31m# No error, now safe to assign to logs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1162\u001b[0m               \u001b[0mend_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep_increment\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1163\u001b[0;31m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mend_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1164\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_training\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1165\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/keras/callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m    434\u001b[0m     \"\"\"\n\u001b[1;32m    435\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_should_call_train_batch_hooks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 436\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'end'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    437\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    438\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_test_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook\u001b[0;34m(self, mode, hook, batch, logs)\u001b[0m\n\u001b[1;32m    276\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_begin_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    277\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'end'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 278\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_end_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    279\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    280\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Unrecognized hook: {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_end_hook\u001b[0;34m(self, mode, batch, logs)\u001b[0m\n\u001b[1;32m    296\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_times\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_time\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 298\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_hook_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhook_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    299\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    300\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_times\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_batches_for_timing_check\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook_helper\u001b[0;34m(self, hook_name, batch, logs)\u001b[0m\n\u001b[1;32m    336\u001b[0m       \u001b[0mhook\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    337\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'_supports_tf_logs'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 338\u001b[0;31m         \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    339\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    340\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnumpy_logs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Only convert once.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/keras/callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m   1042\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1043\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1044\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_update_progbar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1045\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1046\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_test_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/keras/callbacks.py\u001b[0m in \u001b[0;36m_batch_update_progbar\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m   1106\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1107\u001b[0m       \u001b[0;31m# Only block async when verbose = 1.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1108\u001b[0;31m       \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msync_to_numpy_or_python_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1109\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprogbar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinalize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1110\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/keras/utils/tf_utils.py\u001b[0m in \u001b[0;36msync_to_numpy_or_python_type\u001b[0;34m(tensors)\u001b[0m\n\u001b[1;32m    505\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m  \u001b[0;31m# Don't turn ragged or sparse tensors to NumPy.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    506\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 507\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_to_single_numpy_or_python_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    508\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    509\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36mmap_structure\u001b[0;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[1;32m    862\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    863\u001b[0m   \u001b[0mflat_structure\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpand_composites\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mstructure\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 864\u001b[0;31m   \u001b[0mentries\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mflat_structure\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    865\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    866\u001b[0m   return pack_sequence_as(\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    861\u001b[0m                           expand_composites=expand_composites)\n\u001b[1;32m    862\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 863\u001b[0;31m   \u001b[0mflat_structure\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpand_composites\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mstructure\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    864\u001b[0m   \u001b[0mentries\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mflat_structure\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    865\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "base_model.fit(train_features, train_labels, epochs=100,callbacks=[\n",
    "        keras.callbacks.EarlyStopping(patience=8, verbose=1, restore_best_weights=True)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "sweet-share",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 4ms/step - loss: 0.6429 - acc: 0.8856\n",
      "\n",
      "\n",
      "Validation Accuracy: 0.8856304883956909\n"
     ]
    }
   ],
   "source": [
    "val_loss, val_acc = base_model.evaluate(validation_features, validation_labels)\n",
    "print(f'\\n\\nValidation Accuracy: {val_acc}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "starting-complaint",
   "metadata": {},
   "source": [
    "##### This model did a lot better!!!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sapphire-wagon",
   "metadata": {},
   "source": [
    "**More Layers + Regularization to account for lower accuracy in validation versus training**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "confirmed-tiffany",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_54 (Dense)             (None, 150)               1228950   \n",
      "_________________________________________________________________\n",
      "dropout_15 (Dropout)         (None, 150)               0         \n",
      "_________________________________________________________________\n",
      "dense_55 (Dense)             (None, 125)               18875     \n",
      "_________________________________________________________________\n",
      "dropout_16 (Dropout)         (None, 125)               0         \n",
      "_________________________________________________________________\n",
      "dense_56 (Dense)             (None, 100)               12600     \n",
      "_________________________________________________________________\n",
      "dropout_17 (Dropout)         (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_57 (Dense)             (None, 75)                7575      \n",
      "_________________________________________________________________\n",
      "dropout_18 (Dropout)         (None, 75)                0         \n",
      "_________________________________________________________________\n",
      "dense_58 (Dense)             (None, 50)                3800      \n",
      "_________________________________________________________________\n",
      "dropout_19 (Dropout)         (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_59 (Dense)             (None, 25)                1275      \n",
      "_________________________________________________________________\n",
      "dropout_20 (Dropout)         (None, 25)                0         \n",
      "_________________________________________________________________\n",
      "dense_60 (Dense)             (None, 11)                286       \n",
      "=================================================================\n",
      "Total params: 1,273,361\n",
      "Trainable params: 1,273,361\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "third_model = keras.Sequential([\n",
    "    keras.layers.InputLayer(input_shape=train_features.shape[1:]),\n",
    "    keras.layers.Dense(units=150, activation=\"relu\"),\n",
    "    keras.layers.Dropout(0.05),\n",
    "    keras.layers.Dense(units=125, activation=\"relu\"),\n",
    "    keras.layers.Dropout(0.05),\n",
    "    keras.layers.Dense(units=100, activation=\"relu\"),\n",
    "    keras.layers.Dropout(0.05),\n",
    "    keras.layers.Dense(units=75, activation=\"relu\"),\n",
    "    keras.layers.Dropout(0.05),\n",
    "    keras.layers.Dense(units=50, activation=\"relu\"),\n",
    "    keras.layers.Dropout(0.05),\n",
    "    keras.layers.Dense(units=25, activation=\"relu\"),\n",
    "    keras.layers.Dropout(0.05),\n",
    "    keras.layers.Dense(units=11, activation= \"softmax\"),\n",
    "])\n",
    "\n",
    "third_model.compile(\"nadam\", loss=\"categorical_crossentropy\", metrics=[\"acc\"])\n",
    "\n",
    "third_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "motivated-madison",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/22\n",
      "50/50 [==============================] - 2s 12ms/step - loss: 2.2376 - acc: 0.1863\n",
      "Epoch 2/22\n",
      "50/50 [==============================] - 1s 12ms/step - loss: 1.3760 - acc: 0.5375\n",
      "Epoch 3/22\n",
      "50/50 [==============================] - 1s 13ms/step - loss: 0.8551 - acc: 0.7287\n",
      "Epoch 4/22\n",
      "50/50 [==============================] - 1s 13ms/step - loss: 0.5546 - acc: 0.8364\n",
      "Epoch 5/22\n",
      "50/50 [==============================] - 1s 12ms/step - loss: 0.4216 - acc: 0.8599\n",
      "Epoch 6/22\n",
      "50/50 [==============================] - 1s 12ms/step - loss: 0.2896 - acc: 0.9127\n",
      "Epoch 7/22\n",
      "50/50 [==============================] - 1s 13ms/step - loss: 0.2678 - acc: 0.9057\n",
      "Epoch 8/22\n",
      "50/50 [==============================] - 1s 14ms/step - loss: 0.1543 - acc: 0.9606\n",
      "Epoch 9/22\n",
      "50/50 [==============================] - 1s 13ms/step - loss: 0.2377 - acc: 0.9299\n",
      "Epoch 10/22\n",
      "50/50 [==============================] - 1s 13ms/step - loss: 0.1406 - acc: 0.9602\n",
      "Epoch 11/22\n",
      "50/50 [==============================] - 1s 20ms/step - loss: 0.1269 - acc: 0.9598\n",
      "Epoch 12/22\n",
      "50/50 [==============================] - 1s 13ms/step - loss: 0.0840 - acc: 0.9786\n",
      "Epoch 13/22\n",
      "50/50 [==============================] - 1s 14ms/step - loss: 0.0632 - acc: 0.9824\n",
      "Epoch 14/22\n",
      "50/50 [==============================] - 1s 14ms/step - loss: 0.2536 - acc: 0.9316\n",
      "Epoch 15/22\n",
      "50/50 [==============================] - 1s 13ms/step - loss: 0.0704 - acc: 0.9763\n",
      "Epoch 16/22\n",
      "50/50 [==============================] - 1s 13ms/step - loss: 0.0379 - acc: 0.9937\n",
      "Epoch 17/22\n",
      "50/50 [==============================] - 1s 13ms/step - loss: 0.0431 - acc: 0.9877\n",
      "Epoch 18/22\n",
      "50/50 [==============================] - 1s 14ms/step - loss: 0.0150 - acc: 0.9969\n",
      "Epoch 19/22\n",
      "50/50 [==============================] - 1s 23ms/step - loss: 0.0271 - acc: 0.9924\n",
      "Epoch 20/22\n",
      "50/50 [==============================] - 1s 13ms/step - loss: 0.0285 - acc: 0.9873\n",
      "Epoch 21/22\n",
      "50/50 [==============================] - 1s 13ms/step - loss: 0.0453 - acc: 0.9875\n",
      "Epoch 22/22\n",
      "50/50 [==============================] - 1s 13ms/step - loss: 0.0652 - acc: 0.9855\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fd7f5598d00>"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "third_model.fit(train_features, train_labels, epochs=22)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "celtic-valuation",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 4ms/step - loss: 0.7351 - acc: 0.8680\n",
      "\n",
      "\n",
      "Validation Accuracy: 0.8680351972579956\n"
     ]
    }
   ],
   "source": [
    "val_loss, val_acc = third_model.evaluate(validation_features, validation_labels)\n",
    "print(f'\\n\\nValidation Accuracy: {val_acc}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "soviet-royalty",
   "metadata": {},
   "source": [
    "##### The dropout reg model did not do as well so we will stick with our other model. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
