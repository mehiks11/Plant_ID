{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "young-massachusetts",
   "metadata": {},
   "source": [
    "## Plant Classification MVP\n",
    "\n",
    "This project involves using neural networks and transfer learning to classify leaves by plant type. There are 11 classes total. \n",
    "\n",
    "This notebook will build the final model on all the training and validation data and display the final model metrics. Additionally, I will test out some of my own leaf images to test the model on individual images! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dynamic-preservation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "# display and plotting imports\n",
    "%pylab inline \n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "from IPython.display import SVG\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# sklearn imports\n",
    "from sklearn.metrics import accuracy_score\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers import Dense, Activation, Dropout\n",
    "import os\n",
    "import numpy as np\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "#transfer learning model\n",
    "from tensorflow import keras\n",
    "from keras.applications.vgg16 import VGG16\n",
    "\n",
    "conv_base = VGG16(weights='imagenet',\n",
    "                  include_top=False)\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "electronic-inside",
   "metadata": {},
   "source": [
    "## Pulling in and processing image data (train and test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "incident-circumstances",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = '/Users/mehikapatel/Plant_NN_Project/data'\n",
    "\n",
    "train_dir = os.path.join(base_dir, 'train')\n",
    "test_dir = os.path.join(base_dir, 'test')\n",
    "\n",
    "datagen = ImageDataGenerator(rescale=1./255)\n",
    "batch_size = 20\n",
    "\n",
    "def extract_features(directory, sample_count):\n",
    "    features = np.zeros(shape=(sample_count, 4, 4, 512))\n",
    "    labels = np.zeros(shape=(sample_count,11))\n",
    "    generator = datagen.flow_from_directory(\n",
    "        directory,\n",
    "        target_size=(150, 150),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical')\n",
    "    i = 0\n",
    "    for inputs_batch, labels_batch in generator:\n",
    "        features_batch = conv_base.predict(inputs_batch)\n",
    "        features[i * batch_size : (i + 1) * batch_size] = features_batch\n",
    "        labels[i * batch_size : (i + 1) * batch_size] = labels_batch\n",
    "        i += 1\n",
    "        if i * batch_size >= sample_count:\n",
    "            # Note that since generators yield data indefinitely in a loop,\n",
    "            # we must `break` after every image has been seen once.\n",
    "            break\n",
    "    return features, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "structural-qualification",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1929 images belonging to 11 classes.\n",
      "Found 344 images belonging to 11 classes.\n"
     ]
    }
   ],
   "source": [
    "train_features, train_labels = extract_features(train_dir, 1929)\n",
    "test_features, test_labels = extract_features(test_dir, 344) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "elegant-dancing",
   "metadata": {},
   "outputs": [],
   "source": [
    "#flatten images:\n",
    "train_features = np.reshape(train_featLures, (1929, 4 * 4 * 512))\n",
    "test_features = np.reshape(test_features, (344, 4 * 4 * 512))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "treated-powder",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "aggregate-diameter",
   "metadata": {},
   "source": [
    "## Compile and fit the model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "disabled-packing",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8192,)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_features.shape[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "moral-annotation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_7 (Dense)              (None, 150)               1228950   \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 125)               18875     \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 100)               12600     \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 75)                7575      \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 50)                3800      \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 25)                1275      \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 11)                286       \n",
      "=================================================================\n",
      "Total params: 1,273,361\n",
      "Trainable params: 1,273,361\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "final = keras.Sequential([\n",
    "    keras.layers.InputLayer(input_shape=train_features.shape[1:]),\n",
    "    keras.layers.Dense(units=150, activation=\"relu\"),\n",
    "    keras.layers.Dense(units=125, activation=\"relu\"),\n",
    "    keras.layers.Dense(units=100, activation=\"relu\"),\n",
    "    keras.layers.Dense(units=75, activation=\"relu\"),\n",
    "    keras.layers.Dense(units=50, activation=\"relu\"),\n",
    "    keras.layers.Dense(units=25, activation=\"relu\"),\n",
    "    keras.layers.Dense(units=11, activation= \"softmax\"),\n",
    "])\n",
    "\n",
    "final.compile(\"nadam\", loss=\"categorical_crossentropy\", metrics=[\"acc\"])\n",
    "\n",
    "final.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "internal-pollution",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "61/61 [==============================] - 3s 14ms/step - loss: 1.7226 - acc: 0.4033\n",
      "Epoch 2/50\n",
      "61/61 [==============================] - 1s 13ms/step - loss: 0.8026 - acc: 0.7408\n",
      "Epoch 3/50\n",
      "61/61 [==============================] - 1s 17ms/step - loss: 0.6014 - acc: 0.8123\n",
      "Epoch 4/50\n",
      "61/61 [==============================] - 1s 17ms/step - loss: 0.3986 - acc: 0.8766\n",
      "Epoch 5/50\n",
      "61/61 [==============================] - 1s 12ms/step - loss: 0.2836 - acc: 0.9098\n",
      "Epoch 6/50\n",
      "61/61 [==============================] - 1s 12ms/step - loss: 0.2378 - acc: 0.9196\n",
      "Epoch 7/50\n",
      "61/61 [==============================] - 1s 14ms/step - loss: 0.2485 - acc: 0.9191\n",
      "Epoch 8/50\n",
      "61/61 [==============================] - 1s 12ms/step - loss: 0.1450 - acc: 0.9528\n",
      "Epoch 9/50\n",
      "61/61 [==============================] - 1s 12ms/step - loss: 0.1212 - acc: 0.9606\n",
      "Epoch 10/50\n",
      "61/61 [==============================] - 1s 12ms/step - loss: 0.0991 - acc: 0.9627\n",
      "Epoch 11/50\n",
      "61/61 [==============================] - 1s 13ms/step - loss: 0.0944 - acc: 0.9668\n",
      "Epoch 12/50\n",
      "61/61 [==============================] - 1s 12ms/step - loss: 0.0625 - acc: 0.9772\n",
      "Epoch 13/50\n",
      "61/61 [==============================] - 1s 13ms/step - loss: 0.0775 - acc: 0.9730\n",
      "Epoch 14/50\n",
      "61/61 [==============================] - 1s 13ms/step - loss: 0.0528 - acc: 0.9813\n",
      "Epoch 15/50\n",
      "61/61 [==============================] - 1s 15ms/step - loss: 0.0402 - acc: 0.9850\n",
      "Epoch 16/50\n",
      "61/61 [==============================] - 1s 15ms/step - loss: 0.3073 - acc: 0.9305\n",
      "Epoch 17/50\n",
      "61/61 [==============================] - 1s 19ms/step - loss: 0.1977 - acc: 0.9492\n",
      "Epoch 18/50\n",
      "61/61 [==============================] - 1s 15ms/step - loss: 0.0372 - acc: 0.9896\n",
      "Epoch 19/50\n",
      "61/61 [==============================] - 1s 12ms/step - loss: 0.0445 - acc: 0.9876\n",
      "Epoch 20/50\n",
      "61/61 [==============================] - 1s 12ms/step - loss: 0.1342 - acc: 0.9616\n",
      "Epoch 21/50\n",
      "61/61 [==============================] - 1s 15ms/step - loss: 0.0664 - acc: 0.9787\n",
      "Epoch 22/50\n",
      "61/61 [==============================] - 1s 18ms/step - loss: 0.6347 - acc: 0.8434\n",
      "Epoch 23/50\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.0853 - acc: 0.9725\n",
      "Epoch 24/50\n",
      "61/61 [==============================] - 1s 18ms/step - loss: 0.0516 - acc: 0.9803\n",
      "Epoch 25/50\n",
      "61/61 [==============================] - 1s 21ms/step - loss: 0.0311 - acc: 0.9917\n",
      "Epoch 26/50\n",
      "61/61 [==============================] - 1s 21ms/step - loss: 0.0125 - acc: 0.9964\n",
      "Epoch 27/50\n",
      "61/61 [==============================] - 1s 18ms/step - loss: 0.0114 - acc: 0.9969\n",
      "Epoch 28/50\n",
      "61/61 [==============================] - 1s 18ms/step - loss: 0.0317 - acc: 0.9896\n",
      "Epoch 29/50\n",
      "61/61 [==============================] - 1s 15ms/step - loss: 0.1425 - acc: 0.9689\n",
      "Epoch 30/50\n",
      "61/61 [==============================] - 1s 13ms/step - loss: 0.0099 - acc: 0.9979\n",
      "Epoch 31/50\n",
      "61/61 [==============================] - 1s 13ms/step - loss: 0.0077 - acc: 0.9969\n",
      "Epoch 32/50\n",
      "61/61 [==============================] - 1s 13ms/step - loss: 0.0065 - acc: 0.9979\n",
      "Epoch 33/50\n",
      "61/61 [==============================] - 1s 11ms/step - loss: 0.0054 - acc: 0.9979\n",
      "Epoch 34/50\n",
      "61/61 [==============================] - 1s 11ms/step - loss: 0.0348 - acc: 0.9912\n",
      "Epoch 35/50\n",
      "61/61 [==============================] - 1s 11ms/step - loss: 0.0192 - acc: 0.9943\n",
      "Epoch 36/50\n",
      "61/61 [==============================] - 1s 12ms/step - loss: 0.0238 - acc: 0.9927\n",
      "Epoch 37/50\n",
      "61/61 [==============================] - 1s 12ms/step - loss: 0.0032 - acc: 0.9990\n",
      "Epoch 38/50\n",
      "61/61 [==============================] - 1s 12ms/step - loss: 0.0024 - acc: 0.9990\n",
      "Epoch 39/50\n",
      "61/61 [==============================] - 1s 13ms/step - loss: 0.0021 - acc: 0.9990\n",
      "Epoch 40/50\n",
      "61/61 [==============================] - 1s 13ms/step - loss: 1.0076 - acc: 0.8227\n",
      "Epoch 41/50\n",
      "61/61 [==============================] - 1s 13ms/step - loss: 0.2348 - acc: 0.9238\n",
      "Epoch 42/50\n",
      "61/61 [==============================] - 1s 16ms/step - loss: 0.1770 - acc: 0.9549\n",
      "Epoch 43/50\n",
      "61/61 [==============================] - 1s 21ms/step - loss: 0.0785 - acc: 0.9819\n",
      "Epoch 44/50\n",
      "61/61 [==============================] - 1s 20ms/step - loss: 0.0213 - acc: 0.9959\n",
      "Epoch 45/50\n",
      "61/61 [==============================] - 1s 19ms/step - loss: 0.0286 - acc: 0.9917\n",
      "Epoch 46/50\n",
      "61/61 [==============================] - 2s 28ms/step - loss: 0.0112 - acc: 0.9974: 1s - loss: 0\n",
      "Epoch 47/50\n",
      "61/61 [==============================] - 1s 15ms/step - loss: 0.0058 - acc: 0.9979\n",
      "Epoch 48/50\n",
      "61/61 [==============================] - 1s 13ms/step - loss: 0.0035 - acc: 0.9990\n",
      "Epoch 49/50\n",
      "61/61 [==============================] - 1s 13ms/step - loss: 9.5402e-04 - acc: 1.0000\n",
      "Epoch 50/50\n",
      "61/61 [==============================] - 1s 16ms/step - loss: 6.6691e-04 - acc: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7faac0fc8d30>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final.fit(train_features, train_labels, epochs=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "demanding-walker",
   "metadata": {},
   "source": [
    "### Final Test Accuracy Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "nasty-actress",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 3ms/step - loss: 0.2486 - acc: 0.9331\n",
      "\n",
      "\n",
      "Test Accuracy: 0.9331395626068115\n",
      "\n",
      "\n",
      "Test Loss: 0.24856244027614594\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = final.evaluate(test_features, test_labels)\n",
    "print(f'\\n\\nTest Accuracy: {test_acc}')\n",
    "print(f'\\n\\nTest Loss: {test_loss}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "collect-worthy",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to disk\n"
     ]
    }
   ],
   "source": [
    "# Save our model to use in streamlit!\n",
    "# final.save_weights(\"model.h5\")\n",
    "# serialize model to JSON\n",
    "model_json = final.to_json()\n",
    "with open(\"model.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "# serialize weights to HDF5\n",
    "final.save_weights(\"model.h5\")\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "editorial-england",
   "metadata": {},
   "source": [
    "## Test some hold out images!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "incomplete-roulette",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = '/Users/mehikapatel/Plant_NN_Project/data'\n",
    "\n",
    "holdout_dir = os.path.join(base_dir, 'holdout')\n",
    "\n",
    "\n",
    "datagen = ImageDataGenerator(rescale=1./255)\n",
    "batch_size = 20\n",
    "\n",
    "def extract_features(directory, sample_count):\n",
    "    features = np.zeros(shape=(sample_count, 4, 4, 512))\n",
    "    labels = np.zeros(shape=(sample_count,4))\n",
    "    generator = datagen.flow_from_directory(\n",
    "        directory,\n",
    "        target_size=(150, 150),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical')\n",
    "    i = 0\n",
    "    for inputs_batch, labels_batch in generator:\n",
    "        features_batch = conv_base.predict(inputs_batch)\n",
    "        features[i * batch_size : (i + 1) * batch_size] = features_batch\n",
    "        labels[i * batch_size : (i + 1) * batch_size] = labels_batch\n",
    "        i += 1\n",
    "        if i * batch_size >= sample_count:\n",
    "            # Note that since generators yield data indefinitely in a loop,\n",
    "            # we must `break` after every image has been seen once.\n",
    "            break\n",
    "    return features, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "cooperative-stretch",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4 images belonging to 4 classes.\n"
     ]
    }
   ],
   "source": [
    "plantx, planty = extract_features(holdout_dir, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "sophisticated-briefs",
   "metadata": {},
   "outputs": [],
   "source": [
    "#flatten images:\n",
    "plantx = np.reshape(plantx, (4, 4 * 4 * 512))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "pointed-scheme",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = final.predict_classes(plantx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "juvenile-tucson",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'predictions' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-c121c5a54b77>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpredictions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'predictions' is not defined"
     ]
    }
   ],
   "source": [
    "predictions[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "danish-baltimore",
   "metadata": {},
   "source": [
    "We inputted: Pomegranate, Mango, Lemon, Basil. \n",
    "\n",
    "The model classified these as Pomegranate, Lemon, Lemon, & Guava. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
